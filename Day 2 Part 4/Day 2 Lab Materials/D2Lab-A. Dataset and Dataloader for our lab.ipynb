{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1afe191-5213-431c-8f47-a0502c1670c5",
   "metadata": {},
   "source": [
    "# D2Lab-A. Dataset and Dataloader for our lab\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.0 (01/02/2025)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3\n",
    "- Matplotlib\n",
    "- Numpy\n",
    "- Pandas\n",
    "- Torch\n",
    "- Torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9dd5db-658b-4b9c-8e8b-25f6710a791b",
   "metadata": {},
   "source": [
    "## 0. Imports and CUDA\n",
    "\n",
    "In addition to the libraries mentioned above, you will need the *helper_functions.py* file, which contains a few additional functions that help make this notebook simpler for you (e.g. visualisation, test cases, etc.)\n",
    "\n",
    "Please refrain from modifying said file, but feel free to have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4599aff-3fcc-42ef-b3c1-512ac2ed80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchmetrics.classification import BinaryAccuracy\n",
    "# Helper functions (additional file)\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066fafb-d4f6-4409-a976-6f1d9697fefa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>A note before we start:</b> While not necessary, you might want to run the code for this homework using GPU. It remains possible, however, to use CPU only.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604b237-ac58-4c0d-a041-1dcb704972e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1f34e-653c-4304-8b8a-9ab3d1d62825",
   "metadata": {},
   "source": [
    "## 1. Loading and visualizing the dataset\n",
    "\n",
    "In this first section, we are going to load a dataset from the *'dataset.xlsx'* file.\n",
    "\n",
    "Feel free to have a look at this Excel file if you need.\n",
    "\n",
    "The cells below will define the parameters of our dataset, and load the data from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e4061-ce06-4b56-ae95-4cacdff125db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "np.random.seed(17)\n",
    "min_val = -1\n",
    "max_val = 1\n",
    "n_points = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e97e2e-b953-460d-856c-c9f2bce0e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from file\n",
    "excel_file_path = 'dataset_new.xlsx'\n",
    "val1_list, val2_list, inputs, outputs = load_dataset(excel_file_path = excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a9a0a-cc7b-4595-a58a-fd5a52a73925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data in arrays\n",
    "print(inputs.shape, outputs.shape)\n",
    "print(\"Number of samples with class 0:\", len(outputs) - sum(outputs))\n",
    "print(\"Number of samples with class 1:\", sum(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabff1d-b148-4494-85b3-25f6076bb7cb",
   "metadata": {},
   "source": [
    "The visualization below shows the samples in the dataset, along with their ground truth class (red cross = 1, green dot = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fa03d-d70d-4667-812b-a59c1e9ffbc6",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "plot_dataset(min_val, max_val, val1_list, val2_list, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f1449e-7bbb-4656-b9a0-499b1fb00d65",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 1:</b> Given the code executed above, can you describe the different elements of the Machine Learning problem that we seem to be currently facing? At the moment you should be able to describe the task (T), dataset (D), inputs and outputs (I, O). The model (M) and loss (L) will be discussed later.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 2:</b> What geometric property of the decision boundary makes it challenging for linear models like logistic regression? what concept should we use in our neural network overcome this limitation?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4e25c-cb04-4ea6-8a72-de4e92fa9b50",
   "metadata": {},
   "source": [
    "## 2. Writing a PyTorch Dataset object\n",
    "\n",
    "Right now, we would like to write a *PyTorch Dataset* object for our Machine Learning problem.\n",
    "\n",
    "Have a look at the incomplete code below, you will recognize that there are several None variables. These variables probably need to be replaced with something else.\n",
    "\n",
    "Once you have figured out the correct values to use in place of the None variables, you should be able to run the function *test_dataset_oject()* below. It will produce two test cases for you, and both should pass for this task to be considered resolved.\n",
    "\n",
    "You class is expected to have the following features.\n",
    "- Initialization (__init__ method): The dataset initializes by reading an Excel file (dataset.xlsx) using Pandas read_excel function and stores it in the dataframe attribute.\n",
    "- Length method (__len__ method): This method should return a certain information about the dataset.\n",
    "- Get item method (__getitem__ method): This method is called when you index into the dataset (e.g., dataset[idx]). It retrieves a single sample from the dataset at the given index idx. It extracts the features x1 and x2 along with the target y from the dataframe for the sample corresponding to the specified index. The features x1 and x2 should be converted into PyTorch tensors of type torch.float32. The target y should also be converted into a PyTorch tensor of type torch.float32. The features should then be stacked together into a single tensor inputs with 2 columns and rows for each sample. Finally, this method should return two values corresponding to the input features tensor inputs and the target tensor y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b872fc-9a4a-4058-9c52-958423e5c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataframe = pd.read_excel('dataset.xlsx')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return None\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Select columns corresponding to the different inputs and outputs from the dataframe we just created.\n",
    "        # And convert to PyTorch tensors\n",
    "        x1 = None\n",
    "        x2 = None\n",
    "        y = None\n",
    "        x1 = torch.tensor(x1, dtype = torch.float32)\n",
    "        x2 = torch.tensor(x2, dtype = torch.float32)\n",
    "        y = torch.tensor(y, dtype = torch.float32)\n",
    "        # Assemble all input features in a single inputs tensor with 2 columns and rows for each sample in the dataset.\n",
    "        inputs = None\n",
    "        return inputs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca3f81-6a13-4d38-adb0-c849f19abf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our PyTorch Dataset object from the class above\n",
    "pt_dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f91da-71d9-4feb-a688-da391bf44d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running test function for our dataset object\n",
    "test_dataset_object(pt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757e8d0-4346-4d5b-a8c4-e6640c058f97",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 3:</b> Show the code for your CustomDataset object, after you have correctly figured out how to replace the different None variables.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 4:</b> What information about the dataset is the __len__ special method supposed to return? What would happen if it returned an incorrect value (e.g., return 0)?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a0b75-f383-4735-832d-fdf16b944cf1",
   "metadata": {},
   "source": [
    "## 3. Writing a Dataloader object\n",
    "\n",
    "Our next task is now to write a PyTorch dataloader object. It will serve as a conveyor belt for our PyTorch dataset object in the previous section.\n",
    "\n",
    "Its objective will be to form mini-batches of size 128, shuffling the samples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088786e-8769-42be-a275-0bed23d69372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2125ad-2c90-4836-ba4d-c6fea36cdb73",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 5:</b> Can you figure out what to put in place of the None variables in the cell below? Show your code in your report.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99555644-6369-4f33-8040-9336594846d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader object\n",
    "pt_dataloader = DataLoader(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14a6a6-e83b-4966-b129-02029619001c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 6:</b> Why is shuffling the dataset important in the DataLoader? What happens if it is turned off?\n",
    "</div> \n",
    "\n",
    "If you have correctly figured out the code for the cell above, the test cases checked by the function *test_dataloader_object()* should all pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27986600-7930-446b-b427-9dc60a724049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running test function for our dataloader object\n",
    "test_dataloader_object(pt_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214cd9f-8c25-40b4-9730-e89e29a11fab",
   "metadata": {},
   "source": [
    "## What is next?\n",
    "\n",
    "Our task continues in the Notebook B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9706cb-f3cf-43fe-a06c-97f1e049372f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
