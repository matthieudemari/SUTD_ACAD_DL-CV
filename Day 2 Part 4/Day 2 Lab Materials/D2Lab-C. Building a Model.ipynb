{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1afe191-5213-431c-8f47-a0502c1670c5",
   "metadata": {},
   "source": [
    "# D2Lab-C. Building a Model\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.0 (01/02/2025)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3\n",
    "- Matplotlib\n",
    "- Numpy\n",
    "- Pandas\n",
    "- Torch\n",
    "- Torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9dd5db-658b-4b9c-8e8b-25f6710a791b",
   "metadata": {},
   "source": [
    "## 0. Imports and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4599aff-3fcc-42ef-b3c1-512ac2ed80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "# Helper functions (additional file)\n",
    "from helper_functions import *\n",
    "#from hidden_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604b237-ac58-4c0d-a041-1dcb704972e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a049e-ea5a-43db-afac-b32600d0bb57",
   "metadata": {},
   "source": [
    "## 0. Before we start\n",
    "\n",
    "Please copy-paste the Notebook A and Notebook B codes for your *CustomDataset* and *WeirdLayer* classes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875cd4eb-7dd2-483d-8cc9-f12e4c8f6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f453b16-1fe1-4fe7-ab85-78684d25657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeirdLayer(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1f34e-653c-4304-8b8a-9ab3d1d62825",
   "metadata": {},
   "source": [
    "We will also reload the dataset from earlier in Notebook 1-A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef4d9c9-c54e-4b7e-8eb1-696dc5a83bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "np.random.seed(17)\n",
    "min_val = -1\n",
    "max_val = 1\n",
    "n_points = 1000\n",
    "# Load dataset from file\n",
    "excel_file_path = 'dataset.xlsx'\n",
    "val1_list, val2_list, inputs, outputs = load_dataset(excel_file_path = excel_file_path)\n",
    "# Visualize data in arrays\n",
    "print(inputs.shape, outputs.shape)\n",
    "print(\"Number of samples with class 0:\", len(outputs) - sum(outputs))\n",
    "print(\"Number of samples with class 1:\", sum(outputs))\n",
    "# Visualize the dataset\n",
    "plot_dataset(min_val, max_val, val1_list, val2_list, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b1e51-696a-4b43-9704-55e361e6fcad",
   "metadata": {},
   "source": [
    "The cell below also needs to be updated with your solution for the Dataloader part in Notebook A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e4645-a732-441d-a6ec-31a672f25821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset object\n",
    "pt_dataset = CustomDataset()\n",
    "# Define batch size\n",
    "batch_size = 128\n",
    "# Create DataLoader object\n",
    "pt_dataloader = DataLoader(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082ce7b-ed6b-42e3-af54-5547d64a826b",
   "metadata": {},
   "source": [
    "## 5. Defining a Neural Network for this task - Part1: Architecture and Forward Propagation\n",
    "\n",
    "In this section, we will establish our Neural Network model for this task. The architecture will consist of:\n",
    "- One WeirdOperation Layer (weird_layer), which takes 2 inputs and produces 32 outputs,\n",
    "- First Linear Layer (hidden1): Takes 32 inputs and produces 64 outputs, followed by a GELU activation function.\n",
    "- Second Linear Layer (hidden2): Takes 64 inputs and produces 32 outputs, followed by a GELU activation function.\n",
    "- Third Linear Layer (hidden3): Takes 32 inputs and produces 16 outputs, followed by a GELU activation function.\n",
    "- Final Linear Layer (fc): Takes 16 inputs and produces 1 output.\n",
    "- Final Activation (sigmoid): Applies a Sigmoid activation to map the output, making it suitable for binary classification.\n",
    "\n",
    "Our Neural Network will use Binary Cross-Entropy as a loss functions (to be stored in the self.loss attribute) and the binary accuracy from the torchmetrics library, stored in the self.accuracy attribute. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 10:</b> Show your final code for the NeuralNetwork class in your report.\n",
    "</div>\n",
    "\n",
    "The code below, will describe our neural network model and a few None variables need to be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9bf07f-f04d-4619-994d-39ca2ddc3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weird_layer = None\n",
    "        self.hidden1 = None \n",
    "        self.hidden2 = None\n",
    "        self.hidden3 = None \n",
    "        self.fc = None \n",
    "        self.activation = None\n",
    "        self.sigmoid = None\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b48d6-41a9-4712-ae12-355b19ae2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network model\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f44c7d-7103-4fa5-b599-dd8ba048b815",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 11:</b> What is the purpose of the Sigmoid activation used in the final layer? Why can't we simply use a Weird layer as the final operation in the forward method?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6153db7-a897-442e-8467-c389ae1373f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44871cfc-957e-494f-be7d-a286bff4a277",
   "metadata": {},
   "source": [
    "## 6. Defining a Neural Network for this task - Part2: BackPropagation and Training\n",
    "\n",
    "Have a look at the code below. The code:\n",
    "- Initializes our model.\n",
    "- Initializes an Adam Optimizer, and asks for 15 iterations of the forward-backprop.\n",
    "- For each mini-batch of data drawn on each iteration, it produces predictions, calculates a loss and calculates the binary accuracy on said samples.\n",
    "- It then backpropagates on the *loss_value* and adjusts the model parameters using *optimizer.step()*.\n",
    "- Finally, it shows a nice display.\n",
    "- \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 12:</b> Why do we use nn.BCELoss(), instead of the Mean Square Error loss for binary classification? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153b229-2eaf-4c27-b306-97542cefbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network model\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# Gradient descent parameters: optimizers, repetitions, etc.\n",
    "num_epochs = 15\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1000,\n",
    "                             betas = (0.9, 0.999),\n",
    "                             eps = 1e-08)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in pt_dataloader:\n",
    "        # Unpack the mini-batch data\n",
    "        inputs_batch, outputs_batch = batch\n",
    "        outputs_re = outputs_batch.to(device).reshape(-1, 1)\n",
    "        inputs_re = inputs_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(inputs_re)\n",
    "        loss_value = model.loss(pred.float(), outputs_re.float())\n",
    "        # Compute binary accuracy\n",
    "        binary_accuracy_value = model.accuracy(pred, outputs_re)\n",
    "    \n",
    "        # Backward pass and optimization\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # Print loss and accuracy\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss_value.item():.4f}, Training Accuracy: {binary_accuracy_value.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1950e48f-b050-425f-a386-f746988e0d06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 13:</b> When running the cell above, it seems the model is not capable of achieving a great accuracy. If anything, it seems to remain stuck at an accuracy of 30% or so. Should we make adjustments in one of our hyperparameters (e.g. the learning rate)? Why is it important to test some values of the hyperparameters?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 14:</b> Assuming you figured out what was wrong in Question 13, show in your report how you resolved the problem in the code above.\n",
    "Your model should be able to produce a final training accuracy above 90%.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e48377-e866-4525-852a-b465650e1e1b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 15:</b> How can we improve the generalization ability of a model? Please list at least two methods and explain their principles.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question 16:</b> Having figured out how to prove/disprove generalization in Question 15, we leave the rest of the notebook cells for you to play with the code and figure out how to prove that your model is indeed capable of generalization (or not). Show your code, your results and how it matches the reasoning you described in Question 16. Conclude and show the performance of your final model!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5feb3c5b0698db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
